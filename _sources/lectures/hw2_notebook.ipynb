{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16) HW2 solution\n",
    "\n",
    "We want to solve the matrix multiplication problem\n",
    "\n",
    "$$\n",
    "  C := C + A B^{T}. \\qquad \\qquad \\qquad \\qquad \\hbox{(1)}\n",
    "$$\n",
    "\n",
    "Here $A$, $B$, and $C$ have sizes $m \\times k$, $n \\times k$, and $m \\times n$, respectively. Using the same [notation](https://sdsu-comp605.github.io/spring25/lectures/module2-2_cpu_optimization.html#notation) that we've seen in class, where capital letters are typically for matrices, and lower case Greek letters for floating point scalars: $\\alpha$ (for entries of the matrix $A$), $\\beta$ (for entries of the matrix $B$), and $\\gamma$ (for entries of the matrix $C$).\n",
    "\n",
    "Recognizing that the $pj$ element of $B^{T}$ is the $jp$ element of $B$, it follows that the $ij$ element of $C$ can be computed as\n",
    "\n",
    "$$\n",
    "  \\gamma_{ij} := \\gamma_{ij} + \\sum_{p = 1}^{k} \\alpha_{ip} \\beta_{jp}.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix times row vector (update rows of `C`) with inner dot product\n",
    "function mygemm_ijp!(C, A, B)\n",
    "  m, k = size(A)\n",
    "  _, n = size(B)\n",
    "  @assert size(B, 1) == k\n",
    "  @assert size(C) == (m, n)\n",
    "\n",
    "  for i = 1:m\n",
    "    for j = 1:n\n",
    "      for p = 1:k\n",
    "        @inbounds C[i, j] += A[i, p] * B[j, p]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "end\n",
    "\n",
    "# matrix times row vector (update rows of `C`) with inner axpy\n",
    "function mygemm_ipj!(C, A, B)\n",
    "  m, k = size(A)\n",
    "  _, n = size(B)\n",
    "  @assert size(B, 1) == k\n",
    "  @assert size(C) == (m, n)\n",
    "\n",
    "  for i = 1:m\n",
    "    for p = 1:k\n",
    "      for j = 1:n\n",
    "        @inbounds C[i, j] += A[i, p] * B[j, p]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "end\n",
    "\n",
    "# Rank one update (repeatedly update all elements of `C`) with outer product\n",
    "# using axpy with rows of `B`\n",
    "function mygemm_pij!(C, A, B)\n",
    "  m, k = size(A)\n",
    "  _, n = size(B)\n",
    "  @assert size(B, 1) == k\n",
    "  @assert size(C) == (m, n)\n",
    "\n",
    "  for p = 1:k\n",
    "    for i = 1:m\n",
    "      for j = 1:n\n",
    "        @inbounds C[i, j] += A[i, p] * B[j, p]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "end\n",
    "\n",
    "# Rank one update (repeatedly update all elements of `C`) with outer product\n",
    "# using axpy with columns of `A`\n",
    "function mygemm_pji!(C, A, B)\n",
    "  m, k = size(A)\n",
    "  _, n = size(B)\n",
    "  @assert size(B, 1) == k\n",
    "  @assert size(C) == (m, n)\n",
    "\n",
    "  for p = 1:k\n",
    "    for j = 1:n\n",
    "      for i = 1:m\n",
    "        @inbounds C[i, j] += A[i, p] * B[j, p]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "end\n",
    "\n",
    "# matrix times column vector (update columns of `C`) with inner axpy\n",
    "function mygemm_jpi!(C, A, B)\n",
    "  m, k = size(A)\n",
    "  _, n = size(B)\n",
    "  @assert size(B, 1) == k\n",
    "  @assert size(C) == (m, n)\n",
    "\n",
    "  for j = 1:n\n",
    "    for p = 1:k\n",
    "      for i = 1:m\n",
    "        @inbounds C[i, j] += A[i, p] * B[j, p]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "end\n",
    "\n",
    "# matrix times column vector (update columns of `C`) with inner dot product\n",
    "function mygemm_jip!(C, A, B)\n",
    "  m, k = size(A)\n",
    "  _, n = size(B)\n",
    "  @assert size(B, 1) == k\n",
    "  @assert size(C) == (m, n)\n",
    "\n",
    "  for j = 1:n\n",
    "    for i = 1:m\n",
    "      for p = 1:k\n",
    "        @inbounds C[i, j] += A[i, p] * B[j, p]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "# What modules / packages do we depend on\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using Printf\n",
    "using Plots\n",
    "default(linewidth=4) # Plots embelishments\n",
    "\n",
    "# To ensure repeatability\n",
    "Random.seed!(777)\n",
    "\n",
    "# Don't let BLAS use lots of threads (since we are not multi-threaded yet!)\n",
    "BLAS.set_num_threads(1)\n",
    "\n",
    "include(\"../julia_codes/hw2_sol/mygemm.jl\")\n",
    "\n",
    "# C := α * A * B + β * C\n",
    "refgemm!(C, A, B) = mul!(C, A, B', one(eltype(C)), one(eltype(C)))\n",
    "\n",
    "# matrix times row vector (update rows of `C`) with inner dot product\n",
    "# mygemm! = mygemm_ijp!\n",
    "\n",
    "# matrix times row vector (update rows of `C`) with inner axpy\n",
    "# mygemm! = mygemm_ipj!\n",
    "\n",
    "# Rank one update (repeatedly update all elements of `C`) with outer product\n",
    "# using axpy with rows of `B`\n",
    "# mygemm! = mygemm_pij!\n",
    "\n",
    "# Rank one update (repeatedly update all elements of `C`) with outer product\n",
    "# using axpy with columns of `A`\n",
    "mygemm! = mygemm_pji!\n",
    "\n",
    "# matrix times column vector (update columns of `C`) with inner axpy\n",
    "# mygemm! = mygemm_jpi!\n",
    "\n",
    "# matrix times column vector (update columns of `C`) with inner dot product\n",
    "# mygemm! = mygemm_jip!\n",
    "\n",
    "num_reps = 3\n",
    "\n",
    "# What precision numbers to use\n",
    "FloatType1 = Float32\n",
    "FloatType2 = Float64\n",
    "\n",
    "@printf(\"size |      reference      |           %s\\n\", mygemm!)\n",
    "@printf(\"     |   seconds   GFLOPS  |   seconds   GFLOPS     diff\\n\")\n",
    "\n",
    "N = 48:48:480\n",
    "best_perf = zeros(length(N))\n",
    "# Size of square matrix to consider\n",
    "for nmk in N\n",
    "  i = Int(nmk / 48)\n",
    "  n = m = k = nmk\n",
    "  @printf(\"%4d |\", nmk)\n",
    "\n",
    "  gflops = 2 * m * n * k * 1e-09\n",
    "\n",
    "  # Create some random initial data\n",
    "  A = rand(FloatType1, m, k)\n",
    "  B = rand(FloatType1, n, k)\n",
    "  C = rand(FloatType1, m, n)\n",
    "\n",
    "  # Make a copy of C for resetting data later\n",
    "  C_old = copy(C)\n",
    "\n",
    "  # \"truth\"\n",
    "  C_ref = A * B' + C\n",
    "\n",
    "  # Compute the reference timings\n",
    "  best_time = typemax(FloatType1)\n",
    "  for iter = 1:num_reps\n",
    "    # Reset C to the original data\n",
    "    C .= C_old;\n",
    "    run_time = @elapsed refgemm!(C, A, B);\n",
    "    best_time = min(run_time, best_time)\n",
    "  end\n",
    "  # Make sure that we have the right answer!\n",
    "  @assert C ≈ C_ref\n",
    "  best_perf[i] = gflops / best_time\n",
    "\n",
    "  # Print the reference implementation timing\n",
    "  @printf(\"  %4.2e %8.2f  |\", best_time, best_perf[i])\n",
    "\n",
    "  # Compute the timing for mygemm! implementation\n",
    "  best_time = typemax(FloatType1)\n",
    "  for iter = 1:num_reps\n",
    "    # Reset C to the original data\n",
    "    C .= C_old;\n",
    "    run_time = @elapsed mygemm!(C, A, B);\n",
    "    best_time = min(run_time, best_time)\n",
    "  end\n",
    "  best_perf[i] = gflops / best_time\n",
    "\n",
    "  # Compute the error (difference between our implementation and the reference)\n",
    "  diff = norm(C - C_ref, Inf)\n",
    "\n",
    "  # Print mygemm! implementations\n",
    "  @printf(\"  %4.2e %8.2f   %.2e\", best_time, best_perf[i], diff)\n",
    "\n",
    "  @printf(\"\\n\")\n",
    "end\n",
    "\n",
    "plot!(N, best_perf, xlabel = \"m = n = k\", ylabel = \"GFLOPs/S\", label = \"$mygemm! $FloatType1\", title = \"Float32 Vs Float64\")\n",
    "\n",
    "\n",
    "## FloatType2\n",
    "\n",
    "@printf(\"size |      reference      |           %s\\n\", mygemm!)\n",
    "@printf(\"     |   seconds   GFLOPS  |   seconds   GFLOPS     diff\\n\")\n",
    "\n",
    "N = 48:48:480\n",
    "best_perf = zeros(length(N))\n",
    "# Size of square matrix to consider\n",
    "for nmk in N\n",
    "  i = Int(nmk / 48)\n",
    "  n = m = k = nmk\n",
    "  @printf(\"%4d |\", nmk)\n",
    "\n",
    "  gflops = 2 * m * n * k * 1e-09\n",
    "\n",
    "  # Create some random initial data\n",
    "  A = rand(FloatType2, m, k)\n",
    "  B = rand(FloatType2, n, k)\n",
    "  C = rand(FloatType2, m, n)\n",
    "\n",
    "  # Make a copy of C for resetting data later\n",
    "  C_old = copy(C)\n",
    "\n",
    "  # \"truth\"\n",
    "  C_ref = A * B' + C\n",
    "\n",
    "  # Compute the reference timings\n",
    "  best_time = typemax(FloatType2)\n",
    "  for iter = 1:num_reps\n",
    "    # Reset C to the original data\n",
    "    C .= C_old;\n",
    "    run_time = @elapsed refgemm!(C, A, B);\n",
    "    best_time = min(run_time, best_time)\n",
    "  end\n",
    "  # Make sure that we have the right answer!\n",
    "  @assert C ≈ C_ref\n",
    "  best_perf[i] = gflops / best_time\n",
    "\n",
    "  # Print the reference implementation timing\n",
    "  @printf(\"  %4.2e %8.2f  |\", best_time, best_perf[i])\n",
    "\n",
    "  # Compute the timing for mygemm! implementation\n",
    "  best_time = typemax(FloatType2)\n",
    "  for iter = 1:num_reps\n",
    "    # Reset C to the original data\n",
    "    C .= C_old;\n",
    "    run_time = @elapsed mygemm!(C, A, B);\n",
    "    best_time = min(run_time, best_time)\n",
    "  end\n",
    "  best_perf[i] = gflops / best_time\n",
    "\n",
    "  # Compute the error (difference between our implementation and the reference)\n",
    "  diff = norm(C - C_ref, Inf)\n",
    "\n",
    "  # Print mygemm! implementations\n",
    "  @printf(\"  %4.2e %8.2f   %.2e\", best_time, best_perf[i], diff)\n",
    "\n",
    "  @printf(\"\\n\")\n",
    "end\n",
    "\n",
    "plot!(N, best_perf, xlabel = \"m = n = k\", ylabel = \"GFLOPs/S\", label = \"$mygemm! $FloatType2\", title = \"Float32 Vs Float64\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By uncommenting each of the individual `my_gemm` with the different loop orderings in the above code, for `Float64` precision, we find that the best loop ordering for this problem is `pji`. Notice that Julia stores matrices in clumn-major order and data in columns are stored contiguously. The `pji` loop ordering performs a rank-one update (it repeatedly updates all elements of $C$) with outer product computed using `axpy` with the column vector $a_p$.\n",
    "\n",
    "$$\n",
    "  a_{p} \\tilde{b}_{p}^T =\n",
    "  \\begin{bmatrix}\n",
    "    a_{p} \\beta_{1p} & \\cdots & a_{p} \\beta_{mp}\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In the code snippet\n",
    "```julia\n",
    "for p = 1:k\n",
    "   for j = 1:n\n",
    "      for i = 1:m\n",
    "         @inbounds C[i, j] += A[i, p] * B[j, p]\n",
    "      end\n",
    "   end\n",
    "end\n",
    "```\n",
    "being `i` the fastest index, each execution of the inner-most loop traverses the $p$-th column of $A$, $ a_{p}$, multiplies it by the $\\beta_{jp}$ entry of $B$ (moving down in the column entries at the next iteration of the `j` loop, facilitating cache reuse), and updates columns of $C$. \n",
    "\n",
    "\n",
    "The following numbers are the result of the executions on my machine:\n",
    "\n",
    "```\n",
    "size |      reference      |           mygemm_ijp!\n",
    "     |   seconds   GFLOPS  |   seconds   GFLOPS     diff\n",
    "  48 |  8.01e-06    27.60  |  1.12e-04     1.97   7.11e-15\n",
    "  96 |  4.83e-05    36.66  |  9.83e-04     1.80   1.78e-14\n",
    " 144 |  1.46e-04    40.88  |  3.45e-03     1.73   2.84e-14\n",
    " 192 |  3.58e-04    39.55  |  8.47e-03     1.67   3.55e-14\n",
    " 240 |  6.21e-04    44.56  |  1.66e-02     1.67   5.68e-14\n",
    " 288 |  1.04e-03    45.74  |  2.91e-02     1.64   1.71e-13\n",
    " 336 |  1.65e-03    45.98  |  4.57e-02     1.66   2.27e-13\n",
    " 384 |  2.47e-03    45.87  |  1.57e-01     0.72   2.70e-13\n",
    " 432 |  3.63e-03    44.47  |  9.70e-02     1.66   2.84e-13\n",
    " 480 |  6.10e-03    36.26  |  1.53e-01     1.45   3.69e-13\n",
    "\n",
    "\n",
    "size |      reference      |           mygemm_ipj!\n",
    "     |   seconds   GFLOPS  |   seconds   GFLOPS     diff\n",
    "  48 |  8.06e-06    27.46  |  6.83e-05     3.24   7.11e-15\n",
    "  96 |  4.79e-05    36.91  |  7.54e-04     2.35   1.78e-14\n",
    " 144 |  1.45e-04    41.06  |  1.84e-03     3.25   2.84e-14\n",
    " 192 |  5.21e-04    27.15  |  1.07e-02     1.33   3.55e-14\n",
    " 240 |  6.73e-04    41.10  |  1.11e-02     2.49   5.68e-14\n",
    " 288 |  1.04e-03    45.78  |  3.44e-02     1.39   1.71e-13\n",
    " 336 |  1.64e-03    46.33  |  5.30e-02     1.43   2.27e-13\n",
    " 384 |  2.44e-03    46.42  |  1.85e-01     0.61   2.70e-13\n",
    " 432 |  3.58e-03    45.06  |  1.13e-01     1.43   2.84e-13\n",
    " 480 |  5.58e-03    39.60  |  1.60e-01     1.38   3.69e-13\n",
    "\n",
    "\n",
    "size |      reference      |           mygemm_pij!\n",
    "     |   seconds   GFLOPS  |   seconds   GFLOPS     diff\n",
    "  48 |  8.06e-06    27.45  |  6.95e-05     3.18   7.11e-15\n",
    "  96 |  4.83e-05    36.66  |  6.73e-04     2.63   1.78e-14\n",
    " 144 |  1.46e-04    40.84  |  1.92e-03     3.10   2.84e-14\n",
    " 192 |  3.30e-04    42.90  |  1.15e-02     1.24   3.55e-14\n",
    " 240 |  8.77e-04    31.52  |  1.62e-02     1.71   5.68e-14\n",
    " 288 |  1.95e-03    24.56  |  3.74e-02     1.28   1.71e-13\n",
    " 336 |  1.65e-03    45.88  |  5.72e-02     1.33   2.27e-13\n",
    " 384 |  2.62e-03    43.23  |  1.83e-01     0.62   2.70e-13\n",
    " 432 |  4.90e-03    32.88  |  1.23e-01     1.31   2.84e-13\n",
    " 480 |  5.94e-03    37.23  |  1.75e-01     1.26   3.69e-13\n",
    "\n",
    "\n",
    "size |      reference      |           mygemm_pji!\n",
    "     |   seconds   GFLOPS  |   seconds   GFLOPS     diff\n",
    "  48 |  8.02e-06    27.58  |  2.07e-05    10.67   7.11e-15\n",
    "  96 |  4.79e-05    36.91  |  1.35e-04    13.10   1.78e-14\n",
    " 144 |  1.46e-04    40.96  |  4.31e-04    13.86   2.84e-14\n",
    " 192 |  3.28e-04    43.12  |  1.21e-03    11.65   3.55e-14\n",
    " 240 |  1.04e-03    26.66  |  3.47e-03     7.96   5.68e-14\n",
    " 288 |  1.08e-03    44.19  |  5.37e-03     8.90   1.71e-13\n",
    " 336 |  1.71e-03    44.50  |  8.59e-03     8.84   2.27e-13\n",
    " 384 |  2.46e-03    46.06  |  1.28e-02     8.84   2.70e-13\n",
    " 432 |  3.52e-03    45.80  |  1.82e-02     8.87   2.84e-13\n",
    " 480 |  4.66e-03    47.48  |  2.52e-02     8.79   3.69e-13\n",
    "\n",
    "\n",
    "size |      reference      |           mygemm_jpi!\n",
    "     |   seconds   GFLOPS  |   seconds   GFLOPS     diff\n",
    "  48 |  8.22e-06    26.92  |  6.79e-05     3.26   7.11e-15\n",
    "  96 |  4.81e-05    36.81  |  5.03e-04     3.51   1.78e-14\n",
    " 144 |  1.46e-04    40.87  |  1.80e-03     3.31   2.84e-14\n",
    " 192 |  3.43e-04    41.29  |  4.41e-03     3.21   3.55e-14\n",
    " 240 |  6.30e-04    43.89  |  8.90e-03     3.11   5.68e-14\n",
    " 288 |  1.44e-03    33.24  |  1.69e-02     2.83   1.71e-13\n",
    " 336 |  1.66e-03    45.60  |  2.48e-02     3.06   2.27e-13\n",
    " 384 |  2.46e-03    46.03  |  3.52e-02     3.22   2.70e-13\n",
    " 432 |  5.47e-03    29.50  |  4.89e-02     3.30   2.84e-13\n",
    " 480 |  5.36e-03    41.30  |  6.70e-02     3.30   3.69e-13\n",
    "\n",
    "\n",
    "size |      reference      |           mygemm_jip!\n",
    "     |   seconds   GFLOPS  |   seconds   GFLOPS     diff\n",
    "  48 |  8.03e-06    27.54  |  9.19e-05     2.41   7.11e-15\n",
    "  96 |  4.81e-05    36.78  |  9.87e-04     1.79   1.78e-14\n",
    " 144 |  1.46e-04    40.82  |  3.36e-03     1.78   2.84e-14\n",
    " 192 |  5.79e-04    24.44  |  8.46e-03     1.67   3.55e-14\n",
    " 240 |  7.41e-04    37.32  |  1.76e-02     1.57   5.68e-14\n",
    " 288 |  1.06e-03    45.07  |  2.90e-02     1.65   1.71e-13\n",
    " 336 |  1.65e-03    45.99  |  4.48e-02     1.69   2.27e-13\n",
    " 384 |  2.43e-03    46.61  |  1.60e-01     0.71   2.70e-13\n",
    " 432 |  4.82e-03    33.43  |  9.61e-02     1.68   2.84e-13\n",
    " 480 |  6.59e-03    33.57  |  1.53e-01     1.44   3.69e-13\n",
    "```\n",
    "\n",
    "And the following figure compares all of the six loop orderings for square matrices filled with `Float64` numbers:\n",
    "\n",
    "![My solution for HW2 showing mygemm_pji is the best loop ordering](../img/assignment2_square_F64.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.6",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
