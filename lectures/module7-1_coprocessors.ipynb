{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e126967",
   "metadata": {},
   "source": [
    "# 25) Coprocessor architectures\n",
    "\n",
    "Last time:\n",
    "\n",
    "- Collective operations\n",
    "- Naive and MST algorithms\n",
    "\n",
    "Today:\n",
    "\n",
    "1. Coprocessor architectures  \n",
    "2. Energy efficiency  \n",
    "3. Programming models for GPUs\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac5eb5",
   "metadata": {},
   "source": [
    "## 1. Coprocessor architectures  \n",
    "\n",
    "[Coprocessors](https://en.wikipedia.org/wiki/Coprocessor) are meant to supplement the functions of the primary processor (the CPU). \n",
    "\n",
    "A single node on the [Summit cupercomputer](https://en.wikipedia.org/wiki/Summit_(supercomputer)) (which held the number 1 position on the TOP500 list from November 2018 to June 2020.):\n",
    "\n",
    "![](https://en.wikichip.org/w/images/0/06/summit_single-node.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9048c7a",
   "metadata": {},
   "source": [
    "Usually, when systems use more than one kind of processor or core, or when different nodes on a cluster have a different number or configurations of CPUs and coprocessors ([GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit)), we talk about [**heterogeneous architectures**](https://en.wikipedia.org/wiki/Heterogeneous_computing).\n",
    "\n",
    "\n",
    "Some examples of supercomputers, most of which made the top of the [**top-500**](https://top500.org/) list (published every year, twice a year: The first of these updates always coincides with the International Supercomputing Conference in June, and the second is presented at the ACM/IEEE Supercomputing Conference in November). \n",
    "\n",
    "\n",
    "See the [top-500 Wiki page](https://en.wikipedia.org/wiki/TOP500) for reference:\n",
    "\n",
    "* CUDA devices (NVIDIA)\n",
    "  * Programmable via **CUDA**, OpenACC, OpenMP-6, OpenCL, HIP->CUDA, SYCL->CUDA\n",
    "  * Example machine: [OLCF Summit](https://en.wikichip.org/wiki/supercomputers/summit) \n",
    "* ROCm devices (AMD)\n",
    "  * Programmable via **HIP**, OpenMP-6, OpenCL, SYCL->HIP\n",
    "  * Example machines: \n",
    "    - [OLCF Frontier](https://en.wikipedia.org/wiki/Frontier_(supercomputer)), the world's **first exascale supercomputer**. It was the fastest supercomputer in the world between 2022 and 2024 (superseded by El Capitan). [Spec sheet](https://www.olcf.ornl.gov/wp-content/uploads/2019/05/frontier_specsheet_v4.pdf).\n",
    "    - [LLNL El Capitan](https://en.wikipedia.org/wiki/Fugaku_(supercomputer)) (AMD 4th Gen EPYC 24C \"Genoa\" 24-core 1.8 GHz CPUs and AMD Instinct MI300A GPUs).\n",
    "* Intel X GPUs\n",
    "  * Programmable via **SYCL**, OpenMP-6, OpenCL?\n",
    "  * Example machine: [ALCF Aurora/A21](https://www.anl.gov/aurora)\n",
    "* Non-coprocessor supercomputers:\n",
    "  * [Fugaku (Post-K)](https://en.wikipedia.org/wiki/Fugaku_(supercomputer)) It became the fastest supercomputer in the world in the June 2020 TOP500 list as well as becoming the first ARM architecture-based computer to achieve this. Fugaku was superseded as the fastest supercomputer in the world by Frontier in May 2022.\n",
    "  * [TACC Frontera](https://www.tacc.utexas.edu/systems/frontera)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625df8d",
   "metadata": {},
   "source": [
    "### Fundamental capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10763d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "data = \"\"\"\n",
    "package,cores,lanes/core,clock (MHz),peak (GF),bandwidth (GB/s),TDP (W),MSRP\n",
    "Xeon 8280,28,8,2700,2400,141,205,10000\n",
    "NVIDIA V100,80,64,1455,7800,900,300,10664\n",
    "AMD MI60,64,64,1800,7362,1024,300,\n",
    "AMD Rome,64,4,2000,2048,205,200,6450\n",
    "\"\"\"\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "df = CSV.File(IOBuffer(data)) |> DataFrame\n",
    "\n",
    "# Set the index column to \"package\"\n",
    "df.package .= String.(df.package);  # Ensure package names are strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aae5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967833f3",
   "metadata": {},
   "source": [
    "## 2. Energy efficiency\n",
    "\n",
    "### [Amdahl's Law](https://en.wikipedia.org/wiki/Amdahl%27s_law) for energy efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute efficiency (GF/W) and add it as a new column\n",
    "df[!, :efficiency_GF_per_W] = df.\"peak (GF)\" ./ df.\"TDP (W)\"\n",
    "println(df[:, [:package, :efficiency_GF_per_W]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7924853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "default(linewidth=4, legendfontsize=12)\n",
    "\n",
    "ngpu = 0:8\n",
    "overhead = 100  # Power supply, DRAM, disk, etc.\n",
    "\n",
    "# Compute peak performance\n",
    "peak = (ngpu .== 0) .* df[df.package .== \"Xeon 8280\", :\"peak (GF)\"][1] .+ ngpu .* df[df.package .== \"NVIDIA V100\", :\"peak (GF)\"][1]\n",
    "\n",
    "# Compute total power consumption\n",
    "tdp = overhead .+ df[df.package .== \"Xeon 8280\", :\"TDP (W)\"][1] .+ ngpu .* df[df.package .== \"NVIDIA V100\", :\"TDP (W)\"][1]\n",
    "\n",
    "# Plot\n",
    "plot(ngpu, peak ./ tdp, xlabel=\"Number of GPUs per CPU\", title=\"Peak efficiency [GF/W]\", label = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debc590",
   "metadata": {},
   "source": [
    "#### Compare to [Green 500 list](https://www.top500.org/lists/green500/2024/11/)\n",
    "\n",
    "As of [November 2024](https://top500.org/lists/green500/2024/11/):\n",
    "* [#1 system: JEDI (JUPITER Exascale Development Instrument at EuroHPC/FZJ in Germany)](https://www.top500.org/system/180269/) is **72.733 GF/W** (BullSequana XH3000 machine with an NVIDIA Grace Hopper Superchip 72C)\n",
    "* [#2 system: ROMEO HPC Center - Champagne- Ardenne in France](https://www.top500.org/system/180311/) is **70.912 GF/W** (ROMEO-2025 - BullSequana XH3000, Grace Hopper Superchip 72C 3GHz, NVIDIA GH200 Superchip)\n",
    "* [#3 system: Adastra 2 - Grand Equipement National de Calcul Intensif (France)](https://www.top500.org/system/180319/) is **69.098 GF/W** (HPE Cray EX255a, AMD 4th Gen EPYC 24C 1.8GHz, AMD Instinct MI300A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e89c0",
   "metadata": {},
   "source": [
    "### Amdahl's law for cost efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c421bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cost efficiency (GF per dollar) and add it as a new column\n",
    "df[!, :cost_GF_per_dollar] = df.\"peak (GF)\" ./ df.MSRP\n",
    "\n",
    "println(df[:, [:package, :cost_GF_per_dollar]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "overhead = 3000 .+ 2000 * ngpu  # power supply, memory, cooling, maintenance\n",
    "\n",
    "cost = overhead .+ df[df.package .== \"Xeon 8280\", :\"MSRP\"][1] .+ ngpu * df[df.package .== \"NVIDIA V100\", :\"MSRP\"][1]\n",
    "\n",
    "plot(ngpu, peak ./ cost, xlabel=\"number of GPUs per CPU\", title=\"cost efficiency [GF/\\$]\", label = \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29e10b",
   "metadata": {},
   "source": [
    "### What fraction of datacenter cost goes to the power bill?\n",
    "\n",
    "* OLCF Summit is reportedly a \\$200M machine.\n",
    "* What if we just buy the GPUs at retail?\n",
    "  * 256 racks\n",
    "  * 18 nodes per rack\n",
    "  * 6 GPUs per node\n",
    "  * V100 MSRP of about \\$10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e3a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "256 * 18 * 6 * 10e3 / 1e6 # millions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f61db5",
   "metadata": {},
   "source": [
    "~\\$276 M\n",
    "\n",
    "* Rule of thumb: $ \\lesssim \\$1M $ per MW-year\n",
    "* We know Summit is a 13 MW facility\n",
    "* Check [industrial electricity rates](https://www.electricitylocal.com/states/tennessee/knoxville/) in Tennessee (piture below from 2019)\n",
    "\n",
    "![](../img/knoxville-electricity.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d87fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    ".0638 * 24 * 365"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d1e428",
   "metadata": {},
   "source": [
    "Hence, 558.8 * 13 ~  roughly \\$7 million/year in raw electricity to power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317c683",
   "metadata": {},
   "source": [
    "## 3. Programming models for GPUs\n",
    "\n",
    "* Directives\n",
    "  * [OpenMP-6](https://www.openmp.org/resources/refguides/)\n",
    "  * [OpenACC](https://www.openacc.org/) (As in OpenMP, the programmer can annotate native C, C++ and Fortran source code to identify the areas that should be accelerated using compiler directives and additional functions.)\n",
    "\n",
    "Example:\n",
    "\n",
    "A C snippet annotated with OpenACC directives:\n",
    "\n",
    "```c\n",
    "#pragma acc data copy(A) create(Anew)\n",
    "while ( error > tol  &&  iter  <  iter_max )  {\n",
    "  error = 0.0;\n",
    "#pragma acc kernels {\n",
    "#pragma acc loop independent collapse(2)\n",
    "  for (  int  j = 1; j < n-1;  j++ )  {\n",
    "    for (  int  i = 1; i < m-1; i++ )  {\n",
    "       Anew [j] [i] = 0.25 * ( A [j] [i+1] + A [j] [i-1] +\n",
    "                                      A [j-1] [i] + A [j+1] [i]);\n",
    "       error = max ( error, fabs (Anew [j] [i] - A [j] [i]));\n",
    "      }\n",
    "    }\n",
    "  } \n",
    "}\n",
    "```\n",
    "\n",
    "In the above example, we see the use of OpenACC's `data` directive that tells the compiler to create code that performs specific data movements and provides hints about data usage. \n",
    "\n",
    "The directive is `acc data`. The two clauses used in this example that can be combined with the data directive are:\n",
    "\n",
    "- `copy`  \n",
    "  * `copy`, copies data to and from the host and accelerator. When entering the data region, the application allocates accelerator memory and then copies data from the host to the GPU. When exiting the data region, the data from the accelerator is copied back to the host. \n",
    "- `create`  \n",
    "  * `create`, allocates memory on the accelerator when the accelerated region is entered and deallocates the memory when the accelerated region is exited. No data is copied to or from the host and the accelerator. Because the data is local to the accelerator, you can think of it as temporary.\n",
    "\n",
    "- In C, the beginning and end of the _data region_ is marked with {curly braces}.\n",
    "  ```c\n",
    "  #pragma acc data (clause)\n",
    "  {\n",
    "\n",
    "  ...\n",
    "\n",
    "  }\n",
    "  ``` \n",
    "- In Fortran, the _data region_ begins with the data directive and has another directive to specify the end of the data region.\n",
    "  ```fortran\n",
    "  !$acc data (clause)\n",
    "\n",
    "  ..\n",
    "\n",
    "  !$acc end data\n",
    "  ```\n",
    "\n",
    "* After `A` is copied from the host to the accellerator (with the `data copy` directive) and `Anew` is created on the device (with the `data create` directive), the loop then is run on the accelerator by the `acc parallel loop` directive. After the loop is finished, the array `A` is copied from the accelerator back to the host courtesy of the `acc end data` directive for Fortran or the closing curly brace (for C code).\n",
    "\n",
    "* OpenACC allows you to combine directives into a single line, so in the example above we see `acc loop independent collapse(2)`. When used within a parallel region, the `loop` directive asserts that the loop iterations are _independent_ of each other and are safe the parallelize and should be used to provide the compiler as much information about the loops as possible.\n",
    "\n",
    "* Finally, the other clause we see in the example is the `acc kernels` clause. With `kernels` the compiler will determine which loops to parallelize. The `kernels` construct identifies a region of code that may contain parallelism, but relies on the automatic parallelization capabilities of the compiler to analyze the region, identify which loops are safe to parallelize, analyze these loops for data independence, and then accelerate those loops. \n",
    "\n",
    "> For more OpenACC directives and levels of parallelism, read this [guide](https://www.openacc.org/sites/default/files/inline-files/OpenACC_Programming_Guide_0.pdf).\n",
    "\n",
    "### A more direct approach to GPU programming\n",
    "\n",
    "- GPUs have been designed to execute many similar commands, or _threads_, in parallel, achieving higher throughput. Latency is the time between starting an operation and receiving its result, such as 2 ns, while throughput is the rate of completed operations, for example, operations per second.\n",
    "\n",
    "**Resources:**\n",
    "\n",
    "* Thread \"kernel\" and control:\n",
    "  * [CUDA](https://devblogs.nvidia.com/even-easier-introduction-cuda/)\n",
    "  * [HIP](https://rocm.docs.amd.com/projects/HIP/en/latest/understand/programming_model.html) ([video](https://vimeo.com/channels/olcftraining/359154970))\n",
    "* C++ templated/abstractions:\n",
    "  * [SYCL](https://www.khronos.org/sycl/) (abstractions to enable heterogeneous device programming)\n",
    "  * [Kokkos](https://github.com/kokkos/kokkos)\n",
    "  * [Raja](https://github.com/LLNL/RAJA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14bb2a8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.6",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
