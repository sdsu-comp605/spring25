{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20) Parallel Linear Algebra\n",
    "\n",
    "Last time:\n",
    "\n",
    "- Introduction to Batch Jobs and Job Scripting\n",
    "- SLURM Demo\n",
    "\n",
    "Today:\n",
    "1. Parallel inner and outer products  \n",
    "  1.1 OpenMP\n",
    "  1.2 MPI\n",
    "2. Parallel matrix-vector products\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parallel inner and outer products\n",
    "\n",
    "### Inner product\n",
    "\n",
    "For given vectors $x$ and $y$, we want to compute their inner (dot) product\n",
    "\n",
    "$$\n",
    "x^T y = \\sum_{i=1}^N x_i y_i\n",
    "$$\n",
    "\n",
    "### 1.1 OpenMP\n",
    "\n",
    "If we were to use multi-threading via OpenMP, the vectors `x` and `y` of length `N` are stored in a contiguous array in **shared memory**.\n",
    "\n",
    "A C snippet would look like the following:\n",
    "\n",
    "```c\n",
    "double sum = 0;\n",
    "#pragma omp parallel for reduction(+:sum)\n",
    "for (int i=0; i<N; i++)\n",
    "    sum += x[i] * y[i];\n",
    "```\n",
    "\n",
    "### 1.2 MPI\n",
    "\n",
    "If we were to use multi-processing via MPI, the vectors `x` and `y` are _partitioned_ into $P$ parts of length $n_p$ such that:\n",
    "\n",
    "$$\n",
    "N = \\sum_{p=1}^P n_p .\n",
    "$$\n",
    "\n",
    "In the following C snippet the inner product is computed via\n",
    "\n",
    "```c\n",
    "double sum = 0;\n",
    "for (int i=0; i<n; i++)\n",
    "    sum += x[i] * y[i];\n",
    "MPI_Allreduce(MPI_IN_PLACE, &sum, 1, MPI_DOUBLE, MPI_SUM, comm);\n",
    "```\n",
    "\n",
    "Things to consider:\n",
    "\n",
    "* Work: $2N$ flops processed at a rate $R$\n",
    "* Execution time: $\\frac{2N}{RP} + \\text{latency}$\n",
    "* How big is latency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "default(linewidth=4) # Plots embelishments\n",
    "\n",
    "P = 10 .^ range(log10(2), log10(1e6), length=100)\n",
    "N = 1e9         # Length of vectors\n",
    "R = 10e9 / 8    # (10 GB/s per core) (2 flops/16 bytes) = 10/8 GF/s per core\n",
    "t1 = 2e-6       # 2 µs message latency\n",
    "\n",
    "function time_compute(P)\n",
    "    return 2 * N ./ (R .* P)\n",
    "end\n",
    "\n",
    "plot(P, time_compute(P) .+ t1 .* (P .- 1), label=\"linear\", xscale=:log10, yscale=:log10)\n",
    "plot!(P, time_compute(P) .+ t1 .* 2 .* (sqrt.(P) .- 1), label=\"2D mesh\")\n",
    "plot!(P, time_compute(P) .+ t1 .* log2.(P), label=\"hypercube\", legend=:bottomleft)\n",
    "xlabel!(\"P processors\")\n",
    "ylabel!(\"Execution time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network effects\n",
    "\n",
    "Remember that we saw a plot from [Paul Fischer's page](https://www.mcs.anl.gov/~fischer/gop/), researcher at Argonne National Labb and Professor at UIUC, testing different Border Gateway Protocols [(BGP)](https://en.wikipedia.org/wiki/Border_Gateway_Protocol).\n",
    "\n",
    "Here is a different plot comparing \"software `all_reduce`\", meaning traditional MPI based implementation Vs \"hardware-accellerated `all_reduce`\", meaning using GPU-aware MPI:\n",
    "\n",
    "![Tests for MPIAllReduce](../img/FischerBGQAllReduce.png)\n",
    "\n",
    "We noticed how the time is basically independent of the number of processes $P$, and only a small multiple of the cost to send a single message. We attributed this to the good quality of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "source": [
    "#### Torus topology\n",
    "\n",
    "Networks can be connected with different topologies. \n",
    "\n",
    "For instance, the torus topology:\n",
    "\n",
    "![Torus gif](https://upload.wikimedia.org/wikipedia/commons/6/60/Torus_from_rectangle.gif)\n",
    "\n",
    "![Torus image](https://upload.wikimedia.org/wikipedia/commons/1/1f/3d_torus.png)\n",
    "\n",
    "* 3D torus: IBM BlueGene/L (2004) and BlueGene/P (2007)\n",
    "* 5D torus: IBM BlueGene/Q (2011)\n",
    "* 6D torus: Fujitsu K computer (2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dragonfly topology\n",
    "\n",
    "![Cray DragonFly topology](../img/CrayAriesDragonfly.png)\n",
    "\n",
    "#### Today's research: reducing contention and interference\n",
    "\n",
    "Different vendors might provide different solutions. Here is an example from a few years ago highlighting the capabilities of Cray's Slingshot network that still illustrates the concept for different protocols and congestion control:\n",
    "\n",
    "![Cray Slingshot different Ethernet protocols](https://www.nextplatform.com/wp-content/uploads/2019/08/cray-slingshot-hpc-ethernet-protocol.png)\n",
    "\n",
    "![Cray Slingshot congestion control](https://www.nextplatform.com/wp-content/uploads/2019/08/cray-slingshot-congestion-control.png)\n",
    "\n",
    "> There are three workloads running in the system. The red line is a spikey global synchronization routine, the green one is a many to one collective operation, and the blue one is an all to all scatter operation. This shows Slingshot running with congestion control turned off and then turned on. In the top scenario, the red workload spikes right out of the gate, wildly reduces the blue workload and pulls down the green workload. As they are crashing because of backed up packets, the global synchronization tries to send out another pulse, and it gets stepped on, and it goes totally flat as the blue all to all communication takes over and the green many to one collective finishes up, leaving it some breathing room. Finally, after they are pretty much done, the global synchronization spikes up and down like crazy, finishing its work only because it pretty much as the network to itself. The whole mess takes 2 milliseconds to complete, and no one is happy. \n",
    "\n",
    "Here is another simulation showing the latency of traces on the network with a bunch of applications running, some of them causing congestion:\n",
    "\n",
    "![Cray Slingshot trace latency](https://www.nextplatform.com/wp-content/uploads/2019/08/cray-slingshot-trace-latency.png)\n",
    "\n",
    "Images from [this article](https://www.nextplatform.com/2019/08/16/how-cray-makes-ethernet-suited-for-hpc-and-ai-with-slingshot/).\n",
    "\n",
    "##### Compare to BG/Q\n",
    "* Each job gets an electrically isolated 5D torus\n",
    "* Excellent performance and reproducibility\n",
    "* Awkward constraints on job size, lower system utilization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer product\n",
    "\n",
    "\n",
    "$$ C_{ij} = x_i y_j $$\n",
    "\n",
    "* Data in: $2N$\n",
    "* Data out: $N^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parallel matrix-vector products\n",
    "\n",
    "\n",
    "$$ y_i = \\sum_{j} A_{ij} x_j $$\n",
    "\n",
    "How to partition the matrix $A$ across $P$ processors?\n",
    "\n",
    "### 1D row partition\n",
    "\n",
    "* Every process needs entire vector $x$: `MPI_Allgather`\n",
    "* Matrix data does not move\n",
    "* Execution time\n",
    "$$ \\underbrace{\\frac{2N^2}{RP}}_{\\text{compute}} + \\underbrace{t_1 \\log_2 P}_{\\text{latency}} + \\underbrace{t_b N \\frac{P-1}{P}}_{\\text{bandwidth}} $$\n",
    "\n",
    "![Matvec row partition](../img/05-matvec-row.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D partition\n",
    "\n",
    "* Blocks of size $N/\\sqrt{P}$\n",
    "* \"diagonal\" ranks hold the input vector\n",
    "* Broadcast $x$ along columns: `MPI_Bcast`\n",
    "* Perform local compute\n",
    "* Sum `y` along rows: `MPI_Reduce` with roots on diagonal\n",
    "* Execution time\n",
    "$$ \\underbrace{\\frac{2N^2}{RP}}_{\\text{compute}} + \\underbrace{2 t_1 \\log_2 P}_{\\text{latency}} + \\underbrace{\\frac{2 t_b N}{\\sqrt{P}}}_{\\text{bandwidth}} $$\n",
    "\n",
    "![Matvec 2D block partition](../img/05-matvec-block.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1e4\n",
    "tb = 8 * 100 / 1e9 # 8 bytes / (1 GB/s) ~ bandwidth per core in units of double\n",
    "P = 10 .^ range(log10(2), log10(1e6), length=100)\n",
    "t1 = 2e-6       # 2 µs message latency\n",
    "\n",
    "custom_xticks = [10, 100, 1000, 10000, 100000, 1000000]\n",
    "custom_yticks = [.1, .01, .001, .0001]\n",
    "\n",
    "plot(P, (2 * N^2) ./ (R .* P) .+ t1 .* log2.(P) .+ tb .* N .* (P .- 1) ./ P, label=\"1D partition\", xscale=:log10, yscale=:log10, xticks=custom_xticks, yticks=custom_yticks, xlims = [2, 1e6])\n",
    "plot!(P, (2 * N^2) ./ (R .* P) .+ 2 .* t1 .* log2.(P) .+ 2 .* tb .* N ./ sqrt.(P), label=\"2D partition\", xscale=:log10, yscale=:log10, xticks=custom_xticks, yticks=custom_yticks)\n",
    "xlabel!(\"P processors\")\n",
    "ylabel!(\"Execution time\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.6",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
