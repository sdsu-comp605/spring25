{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d3d99e",
   "metadata": {},
   "source": [
    "# 28) Intro to GPU programming in Julia \n",
    "\n",
    "Last time:\n",
    "- Practical CUDA\n",
    "- Memory\n",
    "- Tuckoo demo for CUDA codes\n",
    "\n",
    "Today:\n",
    "1. Intro to GPU programming in Julia (CUDA.jl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3fdc47",
   "metadata": {},
   "source": [
    "## 1. Intro to GPU programming in Julia (CUDA.jl)\n",
    "\n",
    "For GPU programming there are many great resources. Some that I may refer to are:\n",
    "\n",
    ":::{note} References\n",
    "- [Warburton | youtube video](https://www.youtube.com/watch?v=uvVy3CqpVbM) (In the first 47 minutes of the video,Tim gives an excellent introduction to the GPU.)\n",
    "- [Warburton | ATPESC pdf](https://extremecomputingtraining.anl.gov/files/2018/08/ATPESC_2018_Track-2_3_8-2_830am_Warburton-Accelerators.pdf)\n",
    ":::\n",
    "\n",
    "### Add vectors\n",
    "\n",
    "The real \"hello world\" of the GPU is adding vectors:\n",
    "\n",
    "$$\n",
    "C = A + B\n",
    "$$\n",
    "\n",
    "Big ideas:\n",
    "\n",
    "- threads\n",
    "- blocks\n",
    "- how to launch and time kernels\n",
    "- off-loaded memory on the device\n",
    "\n",
    "### Example with [CUDA.jl](https://github.com/JuliaGPU/CUDA.jl)\n",
    "\n",
    "To run this and following Julia CUDA examples, you need to first add [CUDA.jl](https://github.com/JuliaGPU/CUDA.jl) to your environment, with\n",
    "\n",
    "```julia\n",
    "using Pkg\n",
    "Pkg.add(\"CUDA\")\n",
    "```\n",
    "\n",
    "Then you can execute the following script:\n",
    "\n",
    "\n",
    "```{literalinclude} ../julia_codes/module8-1/add_cu_arrays.jl\n",
    ":language: julia\n",
    ":linenos: true\n",
    "```\n",
    "\n",
    "### Memory management\n",
    "\n",
    "As we have seen so far, a crucial aspect of working with a GPU is managing the data on it. \n",
    "\n",
    "The `CuArray` type is the primary interface for doing so: Creating a `CuArray` will allocate data on the GPU, copying elements to it will upload, and converting back to an `Array` will download values to the CPU. Let's see it in an example:\n",
    "\n",
    "```{literalinclude} ../julia_codes/module8-1/copy_cu_array.jl\n",
    ":language: julia\n",
    ":linenos: true\n",
    "```\n",
    "\n",
    "**Observation on garbage collection**:\n",
    "\n",
    "- One striking difference between the native C CUDA implementation and the Julia CUDA.jl interface is that instances of the `CuArray` type are managed by the Julia garbage collector. This means that they will be collected once they are unreachable, and the memory hold by it will be repurposed or freed. There is _no need_ for manual memory management (like the `cudaFree`), just make sure your objects are not reachable (i.e., there are no instances or references).\n",
    "\n",
    "### Reverse vectors\n",
    "\n",
    "The \"hello world 2.0\" of the GPU is (inplace) reverse vector\n",
    "\n",
    "$$\n",
    "A_i := A_{N - i + 1}, \\textrm{with } i = 1, \\ldots, N/2\n",
    "$$\n",
    "\n",
    "Big ideas:\n",
    "\n",
    "- thread independence\n",
    "- [race conditions](https://en.wikipedia.org/wiki/Race_condition)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
